# ubuntu for IB and GPU

```bash
# install add text to kernel, switch to text mode install

# install from aliyun
# https://mirrors.aliyun.com/centos/7.9.2009/os/x86_64/
# https://mirrors.aliyun.com/centos/8.3.2011/BaseOS/x86_64/os/

yum install -y epel-release
yum install -y byobu htop
yum update -y

# vi /etc/default/grub
# GRUB_CMDLINE_LINUX="nofb splash=quiet console=tty0 ... intel_iommu=on iommu=pt default_hugepagesz=1G hugepagesz=1G hugepages=8 rdblacklist=nouveau"

cp /etc/default/grub /etc/default/grub.bak
sed -i '/GRUB_CMDLINE_LINUX/s/rd.lvm.lv=centos_[^[:space:]]*\/swap//'  /etc/default/grub
# https://unix.stackexchange.com/questions/403706/sed-insert-text-after-nth-character-preceding-following-a-given-string
sed -i '/GRUB_CMDLINE_LINUX/s/"/ intel_iommu=on iommu=pt default_hugepagesz=1G hugepagesz=1G hugepages=8 rdblacklist=nouveau"/2' /etc/default/grub

grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg

cat << EOF > /etc/modprobe.d/blacklist-nouveau.conf
blacklist nouveau
options nouveau modeset=0
EOF
dracut --force

umount /home
swapoff  /dev/dm-1

cp /etc/fstab /etc/fstab.bak
sed -i 's/^[^#]*home/#&/' /etc/fstab
sed -i 's/^[^#]*swap/#&/' /etc/fstab

# for 105
lvremove -f /dev/centos_lab105/home
lvremove -f /dev/centos_lab105/swap

lvextend -l +100%FREE /dev/mapper/centos_lab105-root
xfs_growfs /dev/centos_lab105/root

sed -i 's/#GatewayPorts no/GatewayPorts yes/' /etc/ssh/sshd_config
systemctl restart sshd

# for 102
lvremove -f /dev/centos_lab102/home
lvremove -f /dev/centos_lab102/swap

lvextend -l +100%FREE /dev/mapper/centos_lab102-root
xfs_growfs /dev/centos_lab102/root

```

## rancher

```bash
yum remove -y buildah podman skopeo

curl https://releases.rancher.com/install-docker/19.03.sh | sh

systemctl --now enable docker

systemctl --now enable firewalld

firewall-cmd --permanent --add-port=22/tcp
firewall-cmd --permanent --add-port=80/tcp
firewall-cmd --permanent --add-port=443/tcp
firewall-cmd --permanent --add-port=2376/tcp
firewall-cmd --permanent --add-port=2379/tcp
firewall-cmd --permanent --add-port=2380/tcp
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=8472/udp
firewall-cmd --permanent --add-port=9099/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10254/tcp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --permanent --add-port=30000-32767/udp
firewall-cmd --reload

rm -rf ~/.kube/
# https://rancher.com/docs/rancher/v2.x/en/cluster-admin/cleaning-cluster-nodes/
rm -rf /etc/ceph \
       /etc/cni \
       /etc/kubernetes \
       /opt/cni \
       /opt/rke \
       /run/secrets/kubernetes.io \
       /run/calico \
       /run/flannel \
       /var/lib/calico \
       /var/lib/etcd \
       /var/lib/cni \
       /var/lib/kubelet \
       /var/lib/rancher/rke/log \
       /var/log/containers \
       /var/log/kube-audit \
       /var/log/pods \
       /var/run/calico

# https://rancher.com/docs/rancher/v2.5/en/quick-start-guide/deployment/quickstart-manual-setup/
sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443   --privileged rancher/rancher

# https://172.21.6.105

sudo docker run -d --privileged --restart=unless-stopped --net=host -v /etc/kubernetes:/etc/kubernetes -v /var/run:/var/run  rancher/rancher-agent:v2.5.8 --server https://172.21.6.105 --token ms6wpfdr89dw2m685s8dnpg5692zm5pqnhstw5q5l85ddpp9xd2c4n --ca-checksum 32dbcffc3e6248c70c020f6a3e907d3529e439dd33d779e63e802846c0ef42eb --etcd --controlplane --worker

mkdir -p ~/down
cd ~/down

export http_proxy="http://127.0.0.1:18801"
export https_proxy=${http_proxy}

yum install -y wget

wget https://releases.rancher.com/cli2/v2.4.11/rancher-linux-amd64-v2.4.11.tar.gz
tar -xzf rancher-linux-amd64-v2.4.11.tar.gz --strip-components=2 -C /usr/local/bin/

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
mv kubectl /usr/local/bin/

mkdir -p ~/.kube/
vi ~/.kube/config

# gpu operator
# https://rancher.com/blog/2020/get-up-and-running-with-nvidia-gpus

# create namespace: gpu-operator-resources

# helm repo: https://nvidia.github.io/gpu-operator




```