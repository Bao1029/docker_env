# FlexRAN enable on ocp4

本文描述，如何把 intel 的 oran 解决方案 flexran ，移植到 openshift 平台之上。

![](dia/4.10.flexran.drawio.svg)

# prepare public cloud env

我们先在公网环境里面编译镜像，并且上传到quay.io

## basic init setup

```bash

# vultr, ssh enhance

# disable user/passwd login
# ChallengeResponseAuthentication no
# PasswordAuthentication no
# UsePAM no
sed -i 's/PasswordAuthentication yes/PasswordAuthentication no/g' /etc/ssh/sshd_config
sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config

systemctl restart sshd

ssh root@v.redhat.ren -o PubkeyAuthentication=no
# root@v.redhat.ren: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).

subscription-manager register --auto-attach --username ******** --password ********

subscription-manager release --list
subscription-manager release --set=8.4

subscription-manager repos \
    --enable="codeready-builder-for-rhel-8-x86_64-rpms" 

dnf -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm

dnf install -y byobu htop fail2ban

cat << EOF > /etc/fail2ban/jail.d/wzh.conf
[sshd]
enabled = true
# [recidive]
# enabled = true
EOF

systemctl enable --now fail2ban

cat << EOF > /etc/fail2ban/jail.d/wzh.conf
[sshd]
enabled = true
[recidive]
enabled = true
EOF

systemctl restart fail2ban

# byobu
dnf update -y

reboot
```

## install ocp rhcos rt kernel

```bash
mkdir -p /data/ostree

export BUILDNUMBER=4.9.5

wget -O openshift-client-linux-${BUILDNUMBER}.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/${BUILDNUMBER}/openshift-client-linux-${BUILDNUMBER}.tar.gz
wget -O openshift-install-linux-${BUILDNUMBER}.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/ocp/${BUILDNUMBER}/openshift-install-linux-${BUILDNUMBER}.tar.gz

tar -xzf openshift-client-linux-${BUILDNUMBER}.tar.gz -C /usr/local/sbin/
tar -xzf openshift-install-linux-${BUILDNUMBER}.tar.gz -C /usr/local/sbin/

oc image extract --path /:/data/ostree --registry-config /data/pull-secret.json   `  curl -s https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/$BUILDNUMBER/release.txt | grep machine-os-content | awk '{print $2}'  `

mkdir -p /data/dnf
mv /data/ostree/extensions /data/dnf/
rm -rf /data/ostree

mkdir -p /etc/yum.repos.d
cat > /etc/yum.repos.d/rt.repo << 'EOF'
[rt]
name=rt
baseurl=file:///data/dnf/extensions
gpgcheck=0
EOF

dnf install -y kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++

reboot
```
## cache dnf repo 
```bash
mkdir -p /data/dnf
cd /data/dnf

dnf reposync -m --download-metadata --delete -n

dnf copr enable frostyx/modulemd-tools
dnf install -y modulemd-tools 

createrepo ./
repo2module . \
    --module-name foo \
    --module-stream devel \
    --module-version 123 \
    --module-context f32
createrepo_mod .
```

# build flexran with intel icc/icx

```bash
dnf groupinstall -y 'Development Tools'
dnf install -y cmake

# flexran install on host
# yum install centos-release-scl devtoolset-8 -y

# install intel icc icx

cd /data/down
tar zvxf  system_studio_2019_update_3_ultimate_edition_offline.tar.gz

cd /data/down/system_studio_2019_update_3_ultimate_edition_offline

cat > s.cfg << 'EOF'
ACCEPT_EULA=accept
CONTINUE_WITH_OPTIONAL_ERROR=yes
PSET_INSTALL_DIR=/opt/intel
CONTINUE_WITH_INSTALLDIR_OVERWRITE=yes
COMPONENTS=ALL
PSET_MODE=install
ACTIVATION_SERIAL_NUMBER=******************
ACTIVATION_TYPE=serial_number
EOF

./install.sh -s s.cfg

echo "source  /opt/intel/system_studio_2019/bin/compilervars.sh intel64" >> /root/.bashrc  


cd /data/down/

# wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18236/l_BaseKit_p_2021.4.0.3422_offline.sh

bash l_BaseKit_p_2021.4.0.3422_offline.sh

# source /opt/intel/oneapi/setvars.sh
echo "source /opt/intel/oneapi/setvars.sh" >> /root/.bashrc  

```

## download dpdk and patch, and comile flexran sdk

```bash
cd /data/down/

# wget http://static.dpdk.org/rel/dpdk-20.11.3.tar.xz

tar xf dpdk-20.11.3.tar.xz
mv /data/down/dpdk-stable-20.11.3 /opt
cd /opt
ln -s dpdk-stable-20.11.3 dpdk-20.11

export RTE_SDK=/opt/dpdk-20.11
cd $RTE_SDK 
patch -p1 < /data/down/dpdk_patch_21.11.patch

# patch flexran
pip3 install meson ninja
# dnf install -y ninja-build

# dnf install -y cmake

mkdir -p /data/flexran/
cd /data/down
tar zvxf FlexRAN-21.11.tar.gz -C /data/flexran/

export RTE_SDK=/opt/dpdk-20.11
cd /data/flexran
./extract.sh

cd /data/flexran
source set_env_var.sh -d
# for intel: /opt/intel/system_studio_2019/
# for dpdk: /opt/dpdk-20.11

./flexran_build.sh -e -r 5gnr -i avx512 -m sdk

cat <<EOF > /data/flexran/dpdk_build.sh 
#!/bin/bash 

work_path=$PWD
sdk_path=/data/flexran/sdk
echo "------------build base dpdk20.11.3 -------------------" 
cd $RTE_SDK; 
meson build; 
cd build; 
meson configure -Dflexran_sdk=$sdk_path/build-avx512icc/install; 
ninja
EOF

bash /data/flexran/dpdk_build.sh 
# ....................
#         regex/mlx5:     missing internal dependency, "common_mlx5"
#         vdpa/mlx5:      missing internal dependency, "common_mlx5"


# Build targets in project: 991

# DPDK 20.11.3

#   User defined options
#     backend    : ninja
#     flexran_sdk: /data/flexran/sdk/build-avx512icc/install

# Found ninja-1.10.2.git.kitware.jobserver-1 at /usr/local/bin/ninja
# NOTICE: You are using Python 3.6 which is EOL. Starting with v0.62.0, Meson will require Python 3.7 or newer
# [2448/2448] Linking target app/test/dpdk-test

# build flexran

# export CC=icc

cd /data/flexran
./flexran_build.sh -e -r 5gnr -i avx512 -b

dnf install -y podman-docker

export RTE_SDK=/opt/dpdk-20.11
cd /data/flexran
bash ./flexran_build_dockerfile.sh -v -e -i avx512 -r 5gnr -m all

podman image ls
# REPOSITORY                           TAG         IMAGE ID      CREATED         SIZE
# flexran.docker.registry/flexran_vdu  latest      8c5460a697e6  16 minutes ago  1.36 GB
# quay.io/centos/centos                7.9.2009    8652b9f0cb4c  17 months ago   212 MB

podman tag flexran.docker.registry/flexran_vdu:latest  quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-centos-7.9

podman push quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-centos-7.9

```

## vsftpd

我们需要在本地准备一个ftp服务器，来承载rt-kernel的repo，后面编译容器镜像，需要访问这个临时的repo

```bash
dnf install -y vsftpd
sed -i 's/anonymous_enable=NO/anonymous_enable=YES/g' /etc/vsftpd/vsftpd.conf
systemctl disable --now firewalld
systemctl enable --now vsftpd

mkdir -p /var/ftp/dnf
mount --bind /data/dnf /var/ftp/dnf
chcon -R -t public_content_t  /var/ftp/dnf
find /data/dnf/extensions -type f -exec chmod 644 {} \;

chmod +x /etc/rc.d/rc.local
cat << EOF >>/etc/rc.d/rc.local

iptables -A INPUT -d 10.88.0.1 -j ACCEPT
iptables -A INPUT -p tcp --dport 21 -j REJECT

EOF
systemctl enable --now rc-local
```

## flexran_vdu for rhel8.4

```bash
export RTE_SDK=/opt/dpdk-20.11
cd /data/flexran
bash ./flexran_build_dockerfile.wzh.sh -v -e -i avx512 -r 5gnr -m all

podman tag flexran.docker.registry/flexran_vdu:latest  quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-ubi-8.4

podman push quay.io/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-ubi-8.4

```

## copy flexran sdk to image

```bash
cat << 'EOF' > /data/flexran.sdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY flexran /data/flexran
EOF

cd /data
podman build --squash -t quay.io/nepdemo/flexran_basekit:flexran-sdk-21.11-ocp-4.9.5-ubi-8.4 -f flexran.sdk.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:flexran-sdk-21.11-ocp-4.9.5-ubi-8.4
```

## copy intel icc to image

```bash
cat << 'EOF' > /opt/intel/flexran.intel.icc.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY system_studio_2019 /opt/intel/system_studio_2019
COPY licenses /opt/intel/licenses
COPY packagemanager /opt/intel/packagemanager
EOF

cd /opt/intel
podman build --squash -t quay.io/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icc.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4
```

## copy intel icx to image

```bash
cat << 'EOF' > /opt/intel/flexran.intel.icx.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN dnf -y update
RUN dnf -y install rsync

COPY oneapi /opt/intel/oneapi
COPY licenses /opt/intel/licenses
COPY packagemanager /opt/intel/packagemanager
EOF

cd /opt/intel
podman build --squash -t quay.io/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icx.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
```

## build dev docker image with dpdk 20.11

```bash
cat << 'EOF' > /opt/flexran.dpdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN echo -e "\
[localrepo]\n\
name=LocalRepo\n\
baseurl=ftp://10.88.0.1/dnf/extensions/\n\
enabled=1\n\
gpgcheck=0" \
> /etc/yum.repos.d/local.repo

RUN dnf -y update
RUN dnf -y install rsync

RUN dnf -y install kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++ libhugetlbfs-utils libhugetlbfs-devel libhugetlbfs numactl-devel pciutils libaio libaio-devel net-tools libpcap python3-pip
RUN dnf install -y --allowerasing coreutils
RUN dnf groupinstall -y development server
RUN pip-3 install meson ninja

COPY dpdk-stable-20.11.3 /opt/dpdk-stable-20.11.3
RUN ln -s /opt/dpdk-stable-20.11.3 /opt/dpdk-20.11

EOF

cd /opt/
podman build --squash -t quay.io/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 -f flexran.dpdk.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 

```

# build in nepdemo env

在nepdemo的内网环境中，编译镜像，并将镜像推送到nepdemo的镜像仓库

## create a image registry to hold the large container image

```bash
# found a centos7 host

mkdir /etc/crts/ && cd /etc/crts
openssl req \
   -newkey rsa:2048 -nodes -keyout redhat.ren.key \
   -x509 -days 3650 -out redhat.ren.crt -subj \
   "/C=CN/ST=GD/L=SZ/O=Global Security/OU=IT Department/CN=*.redhat.ren"

cp /etc/crts/redhat.ren.crt /etc/pki/ca-trust/source/anchors/
update-ca-trust extract

mkdir -p /home/data/registry
cd /data
# tar zxf registry.tgz
yum -y install docker-distribution

cat << EOF > /etc/docker-distribution/registry/config.yml
version: 0.1
log:
  fields:
    service: registry
storage:
    cache:
        layerinfo: inmemory
    filesystem:
        rootdirectory: /home/data/registry
    delete:
        enabled: true
http:
    addr: :5443
    tls:
       certificate: /etc/crts/redhat.ren.crt
       key: /etc/crts/redhat.ren.key
EOF
# systemctl restart docker
# systemctl stop docker-distribution
systemctl enable --now docker-distribution

```

## build container image for intel sdk

```bash
cat << EOF >>  /etc/hosts
192.168.123.252 reg-tmp.redhat.ren
EOF

export REG_TMP="reg-tmp.redhat.ren:5443"

podman tag flexran.docker.registry/flexran_vdu:latest  ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-ubi-8.4

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-ubi-8.4

# copy flexran sdk to image
cd /data
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-21.11-ocp-4.9.5-ubi-8.4 -f flexran.sdk.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-21.11-ocp-4.9.5-ubi-8.4

# copy intel icc to image
cd /opt/intel
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icc.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4

# copy intel icx to image
cd /opt/intel
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4 -f flexran.intel.icx.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4


# build dev docker image with dpdk 20.11
cat << 'EOF' > /opt/flexran.dpdk.dockerfile
FROM registry.access.redhat.com/ubi8/ubi:8.4

RUN dnf repolist
RUN sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
RUN sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
RUN sed -i 's|cdn.redhat.com|china.cdn.redhat.com|g' /etc/yum.repos.d/redhat.repo
RUN sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
RUN mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak

RUN echo -e "\
[localrepo]\n\
name=LocalRepo\n\
baseurl=ftp://192.168.122.1/dnf/extensions/\n\
enabled=1\n\
gpgcheck=0" \
> /etc/yum.repos.d/local.repo

RUN dnf -y update
RUN dnf -y install rsync

RUN dnf -y install kernel-rt-core kernel-rt-devel kernel-rt-modules kernel-rt-modules-extra kernel-headers libhugetlbfs-devel zlib-devel numactl-devel cmake gcc gcc-c++ libhugetlbfs-utils libhugetlbfs-devel libhugetlbfs numactl-devel pciutils libaio libaio-devel net-tools libpcap python3-pip
RUN dnf install -y --allowerasing coreutils
RUN dnf groupinstall -y development server
RUN pip-3 install meson ninja

COPY dpdk-stable-20.11.3 /opt/dpdk-stable-20.11.3
RUN ln -s /opt/dpdk-stable-20.11.3 /opt/dpdk-20.11

EOF

cd /opt/
podman build --squash -t ${REG_TMP}/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 -f flexran.dpdk.dockerfile ./

podman push --tls-verify=false ${REG_TMP}/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 

```

# deploy on ocp 4.9.5

镜像都准备好了，我们开始在openshift4 上进行部署测试。

## set security for temp image registry

我们临时创建了一个镜像仓库，那么我们就要把这个配置放到集群里面去，主要是让ocp集群，不要检查这个新镜像仓库的证书。

- [How to remove worker role from master in Red Hat OpenShift Container Platform 4.x?](https://access.redhat.com/solutions/4564851)


```bash
oc patch schedulers.config.openshift.io/cluster --type merge -p '{"spec":{"mastersSchedulable":false}}'

install /data/ocp4/clients/butane-amd64 /usr/local/bin/butane

cat << EOF > /data/sno/tmp.images.bu
variant: openshift
version: 4.9.0
metadata:
  labels:
    machineconfiguration.openshift.io/role: worker
  name: 99-zzz-worker-temp-images
storage:
  files:
    - path: /etc/containers/registries.conf.d/temp.registries.conf
      overwrite: true
      contents:
        inline: |

            [[registry]]
            location = "tmp-registry.ocp4.redhat.ren:5443"
            insecure = true
            blocked = false
            mirror-by-digest-only = false
            prefix = ""

EOF

butane /data/sno/tmp.images.bu > /data/sno/99-zzz-worker-temp-images.yaml

oc create -f /data/sno/99-zzz-worker-temp-images.yaml

```

## set a host-path dir for flexran sdk

我们需要在 worker-2 上创建本地目录，好承载 flexran sdk, intel icc, intel icx 等超级大的目录和文件，主要是开发组有在容器平台做开发和测试的需求。如果是生成运行环境，这个本地目录是不应该存在的。

```bash
# do not need, as it is already deployed
cat << EOF > /data/install/host-path.yaml
---
apiVersion: machineconfiguration.openshift.io/v1
kind: MachineConfig
metadata:
  name: 50-set-selinux-for-hostpath-baicell-worker-rt-2
  labels:
    machineconfiguration.openshift.io/role: worker-rt-2
spec:
  config:
    ignition:
      version: 3.2.0
    systemd:
      units:
        - contents: |
            [Unit]
            Description=Set SELinux chcon for hostpath baicell
            Before=kubelet.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStartPre=-mkdir -p /var/baicell
            ExecStart=chcon -Rt container_file_t /var/baicell/

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: hostpath-baicell.service
EOF
oc create -f /data/install/host-path.yaml

```

## using job to copy files to local path

我们使用job的方式，把flexran sdk, intel icc/icx sdk复制到worker-2的本地目录，以便后续使用。用job的方式，主要考虑，这个是一次性的工作，并且我们在container image 里面还装了rsync，这样以后如果破坏了本地目录，重新运行以下job，就可以很快的同步目录。

```bash

export REG_TMP='tmp-registry.ocp4.redhat.ren:5443'

# copy dpdk to local
cat << EOF > /data/install/job.flexran.dpdk.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.dpdk.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 
        command: ["rsync", "--delete", "-arz", "/opt/dpdk-stable-20.11.3", "/nepdemo/"]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/baicell      
EOF

oc create -f /data/install/job.flexran.dpdk.yaml

# copy flexran sdk to local
cat << EOF > /data/install/job.flexran.sdk.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.sdk.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:flexran-sdk-21.11-ocp-4.9.5-ubi-8.4
        command: ["rsync", "--delete", "-arz", "/data/flexran", "/nepdemo/"]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/baicell      
EOF

oc create -f /data/install/job.flexran.sdk.yaml

# copy intel icc sdk to local
cat << EOF > /data/install/job.intel.icc.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icc.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icc-21.11-ocp-4.9.5-ubi-8.4
        command: ["rsync", "--delete", "-arz", "/opt/intel/system_studio_2019", "/nepdemo/"]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/baicell      
EOF

oc create -f /data/install/job.intel.icc.yaml

# copy intel icx sdk to local
cat << EOF > /data/install/job.intel.icx.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icx.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
        command: ["rsync", "--delete", "-arz", "/opt/intel/oneapi", "/nepdemo/"]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/baicell      
EOF

oc create -f /data/install/job.intel.icx.yaml

# copy intel license to local
cat << EOF > /data/install/job.intel.license.yaml
---
apiVersion: batch/v1
kind: Job
metadata:
  name: flexran.basekit.intel.icx.copy
  namespace: default
spec:
  template:
    spec:
      containers:
      - name: files
        image: ${REG_TMP}/nepdemo/flexran_basekit:intel.icx-21.11-ocp-4.9.5-ubi-8.4
        command: [ "/bin/sh","-c","--" ]
        args: ["rsync --delete -arz /opt/intel/licenses /nepdemo/ ; rsync --delete -arz /opt/intel/packagemanager /nepdemo/ "]
        volumeMounts:
          - name: nepdemo
            mountPath: /nepdemo
      restartPolicy: Never
      nodeName: worker-2.ocp4.redhat.ren
      volumes:
        - name: nepdemo
          hostPath:
            path: /var/baicell      
EOF

oc create -f /data/install/job.intel.license.yaml

```

## setup sriov operator

openshift有sriov的operator，官方支持intel x710网卡，我们直接用就好了。

- [Single Root I/O Virtualization (SR-IOV) hardware networks](https://docs.openshift.com/container-platform/4.9/networking/hardware_networks/about-sriov.html)

the env has nic Intel X710 : 8086 1572

```bash
# install sriov operator
cat << EOF > /data/install/sriov.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-sriov-network-operator
  annotations:
    workload.openshift.io/allowed: management
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: sriov-network-operators
  namespace: openshift-sriov-network-operator
spec:
  targetNamespaces:
  - openshift-sriov-network-operator
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: sriov-network-operator-subscription
  namespace: openshift-sriov-network-operator
spec:
  channel: "4.9"
  installPlanApproval: Manual
  name: sriov-network-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/sriov.yaml

```
![](imgs/20220506230756.png)  
```bash
oc get SriovNetworkNodeState -n openshift-sriov-network-operator
# NAME                       AGE
# master-0                   42m
# worker-0.ocp4.redhat.ren   42m
# worker-1                   42m
# worker-2.ocp4.redhat.ren   42m

oc get SriovNetworkNodeState/worker-2.ocp4.redhat.ren -n openshift-sriov-network-operator -o yaml
# apiVersion: sriovnetwork.openshift.io/v1
# kind: SriovNetworkNodeState
# metadata:
#   creationTimestamp: "2022-05-06T14:34:54Z"
#   generation: 1
#   name: worker-2.ocp4.redhat.ren
#   namespace: openshift-sriov-network-operator
#   ownerReferences:
#   - apiVersion: sriovnetwork.openshift.io/v1
#     blockOwnerDeletion: true
#     controller: true
#     kind: SriovNetworkNodePolicy
#     name: default
#     uid: 4eca5eea-e1e5-410f-8833-dd2de1434e53
#   resourceVersion: "70932404"
#   uid: 1d122c8e-b788-4f1e-a3d5-865c6230a476
# spec:
#   dpConfigVersion: "70930693"
# status:
#   interfaces:
#   - deviceID: "1572"
#     driver: i40e
#     linkSpeed: -1 Mb/s
#     linkType: ETH
#     mac: 90:e2:ba:a8:29:e6
#     mtu: 1500
#     name: ens2f0
#     pciAddress: 0000:65:00.0
#     totalvfs: 64
#     vendor: "8086"
#   - deviceID: "1572"
#     driver: i40e
#     linkSpeed: -1 Mb/s
#     linkType: ETH
#     mac: 90:e2:ba:a8:29:e7
#     mtu: 1500
#     name: ens2f1
#     pciAddress: 0000:65:00.1
#     totalvfs: 64
#     vendor: "8086"
#   - deviceID: 37d1
#     driver: i40e
#     linkSpeed: 1000 Mb/s
#     linkType: ETH
#     mac: ac:1f:6b:ea:5b:32
#     mtu: 1500
#     name: eno1
#     pciAddress: 0000:b5:00.0
#     totalvfs: 32
#     vendor: "8086"
#   - deviceID: 37d1
#     driver: i40e
#     linkSpeed: 1000 Mb/s
#     linkType: ETH
#     mac: ac:1f:6b:ea:5b:33
#     mtu: 1500
#     name: eno2
#     pciAddress: 0000:b5:00.1
#     totalvfs: 32
#     vendor: "8086"
#   syncStatus: Succeeded

# how to use the sriov to create VF and attach to pod, depends on use case from nep demo request
# remember to active SRIOV in bios
# remember to active VT-d in bios
cat << EOF > /data/install/sriov.policy.yaml
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: policy-710-nic01-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic01_rt2
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  numVfs: 4
  nicSelector:
    vendor: "8086"
    deviceID: "1572"
    rootDevices:
      - "0000:65:00.0"
    # pfNames:
    #   - "ens2f0"
  # linkType: eth
  # isRdma: false
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: policy-710-nic02-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic02_rt2
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  numVfs: 4
  nicSelector:
    vendor: "8086"
    deviceID: "1572"
    rootDevices:
      - "0000:65:00.1"
    # pfNames:
    #   - "ens2f1"
  # linkType: eth
  # isRdma: false
EOF
oc create -f /data/install/sriov.policy.yaml

# oc delete -f /data/install/sriov.policy.yaml

oc get sriovnetworknodestates/worker-2.ocp4.redhat.ren -n openshift-sriov-network-operator  -o jsonpath='{.status.syncStatus}' && echo
# Succeeded

# oc label node worker-2.ocp4.redhat.ren feature.node.kubernetes.io/network-sriov.capable="true"

# https://docs.openshift.com/container-platform/4.9/networking/hardware_networks/configuring-sriov-ib-attach.html
# Dynamic IP address (DHCP) assignment configuration
# require a dhcp server in cluster
apiVersion: operator.openshift.io/v1
kind: Network
metadata:
  name: cluster
spec:
  additionalNetworks:
  - name: dhcp-shim
    namespace: default
    type: Raw
    rawCNIConfig: |-
      {
        "name": "dhcp-shim",
        "cniVersion": "0.3.1",
        "type": "bridge",
        "ipam": {
          "type": "dhcp"
        }
      }
  # ...

oc get Network.operator.openshift.io/cluster -o yaml
# apiVersion: operator.openshift.io/v1
# kind: Network
# metadata:
#   creationTimestamp: "2021-10-30T04:16:56Z"
#   generation: 2645
#   name: cluster
#   resourceVersion: "71444760"
#   uid: 0f2aede8-0600-40bd-a7d7-c90fee7eb842
# spec:
#   clusterNetwork:
#   - cidr: 10.254.0.0/16
#     hostPrefix: 24
#   defaultNetwork:
#     type: OpenShiftSDN
#   disableNetworkDiagnostics: false
#   logLevel: Normal
#   managementState: Managed
#   observedConfig: null
#   operatorLogLevel: Normal
#   serviceNetwork:
#   - 172.30.0.0/16
#   unsupportedConfigOverrides: null
# status:
#   conditions:
#   - lastTransitionTime: "2021-10-30T04:16:56Z"
#     status: "False"
#     type: ManagementStateDegraded
#   - lastTransitionTime: "2022-05-06T08:06:33Z"
#     status: "False"
#     type: Degraded
#   - lastTransitionTime: "2021-10-30T04:16:56Z"
#     status: "True"
#     type: Upgradeable
#   - lastTransitionTime: "2022-05-07T11:22:52Z"
#     status: "False"
#     type: Progressing
#   - lastTransitionTime: "2021-10-30T04:18:10Z"
#     status: "True"
#     type: Available
#   readyReplicas: 0
#   version: 4.9.5

# if you use ipam dhcp, then you do this, otherwise skip
oc edit Network.operator.openshift.io/cluster

oc get pod -n openshift-multus  | grep dhcp
# dhcp-daemon-4s2c4                     1/1     Running   0          3h11m
# dhcp-daemon-9lvch                     1/1     Running   0          3h11m
# dhcp-daemon-lhss5                     1/1     Running   0          3h11m
# dhcp-daemon-q8qmh                     1/1     Running   0          3h11m

cat << EOF > /data/install/sriov.attach.yaml
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: intel-710-nic01-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic01_rt2
  networkNamespace: vbbu-demo
  ipam: |-
    {
      "type": "static",
      "addresses": [
        {
          "address": "192.168.12.21/24"
        }
      ]
    }
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: intel-710-nic02-rt2
  namespace: openshift-sriov-network-operator
spec:
  resourceName: intel_710_nic02_rt2
  networkNamespace: vbbu-demo
  # ipam: |-
  #   {
  #     "type": "dhcp"
  #   }
  ipam: |-
    {
      "type": "static",
      "addresses": [
        {
          "address": "192.168.22.21/24"
        }
      ]
    }  
EOF
oc create -f /data/install/sriov.attach.yaml

# oc delete -f /data/install/sriov.attach.yaml

oc get net-attach-def -n vbbu-demo
# NAME                  AGE
# intel-710-nic01-rt2   34s
# intel-710-nic02-rt2   34s

```

## setup fec sriov operator

intel已经给自己的FEC加速卡做好了operator，还有非常详细的文档，我们很幸福的直接用就好了。

![](imgs/20220506232629.png)  

- [SEO Operator for Wireless FEC Accelerators documentation](https://github.com/smart-edge-open/sriov-fec-operator/blob/main/spec/openshift-sriov-fec-operator.md)
- [Intel's vRAN accelerators supported by SEO Operators on OpenShift](https://github.com/smart-edge-open/sriov-fec-operator/blob/main/spec/vran-accelerators-supported-by-operator.md)

```bash
# install sriov operator
cat << EOF > /data/install/sriov.fec.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: vran-acceleration-operators
  annotations:
    workload.openshift.io/allowed: management
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: vran-operators
  namespace: vran-acceleration-operators
spec:
  targetNamespaces:
    - vran-acceleration-operators
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: sriov-fec-subscription
  namespace: vran-acceleration-operators
spec:
  channel: stable
  installPlanApproval: Manual
  name: sriov-fec
  source: certified-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/sriov.fec.yaml

oc get csv -n vran-acceleration-operators
# NAME                                DISPLAY                                             VERSION   REPLACES   PHASE
# performance-addon-operator.v4.9.0   Performance Addon Operator                          4.9.0                Succeeded
# sriov-fec.v2.2.1                    SEO SR-IOV Operator for Wireless FEC Accelerators   2.2.1                Succeeded

oc get sriovfecnodeconfig -n vran-acceleration-operators 
# No resources found in vran-acceleration-operators namespace.

cat << EOF > /data/install/sriov.fec.config.yaml
apiVersion: sriovfec.intel.com/v2
kind: SriovFecClusterConfig
metadata:
  name: config
spec:
  priority: 1
  nodeSelector:
    kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  acceleratorSelector:
    pciAddress: 0000:af:00.0
  physicalFunction:  
    pfDriver: "pci-pf-stub"
    vfDriver: "vfio-pci"
    vfAmount: 16
    bbDevConfig:
      acc100:
        # Programming mode: 0 = VF Programming, 1 = PF Programming
        pfMode: false
        numVfBundles: 16
        maxQueueSize: 1024
        uplink4G:
          numQueueGroups: 0
          numAqsPerGroups: 16
          aqDepthLog2: 4
        downlink4G:
          numQueueGroups: 0
          numAqsPerGroups: 16
          aqDepthLog2: 4
        uplink5G:
          numQueueGroups: 4
          numAqsPerGroups: 16
          aqDepthLog2: 4
        downlink5G:
          numQueueGroups: 4
          numAqsPerGroups: 16
          aqDepthLog2: 4
EOF
oc create -f /data/install/sriov.fec.config.yaml

```

## setup ptp

intel flexran文档里面说，必须要用ptp，这个正常，在o-ran架构中，ptp是必须的。

- [Using PTP hardware](https://docs.openshift.com/container-platform/4.9/networking/using-ptp.html)

```bash
# install ptp operator
cat << EOF > /data/install/ptp.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-ptp
  annotations:
    workload.openshift.io/allowed: management
  labels:
    name: openshift-ptp
    openshift.io/cluster-monitoring: "true"
---
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: ptp-operators
  namespace: openshift-ptp
spec:
  targetNamespaces:
  - openshift-ptp
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: ptp-operator-subscription
  namespace: openshift-ptp
spec:
  channel: "4.9"
  installPlanApproval: Manual
  name: ptp-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
oc create -f /data/install/ptp.yaml

oc get csv -n openshift-ptp
# NAME                                DISPLAY                      VERSION              REPLACES   PHASE
# performance-addon-operator.v4.9.0   Performance Addon Operator   4.9.0                           Succeeded
# ptp-operator.4.9.0-202204211825     PTP Operator                 4.9.0-202204211825              Succeeded

oc get csv -n openshift-ptp \
  -o custom-columns=Name:.metadata.name,Phase:.status.phase
# Name                                Phase
# performance-addon-operator.v4.9.0   Succeeded
# ptp-operator.4.9.0-202204211825     Succeeded

# as nepdemo request, disable phc2sys service, but we enabled it.
# 坑爹的 ptp4lConf 配置，我查了源代码才知道，他不能有空行
cat << EOF > /data/install/ptp.config.yaml
apiVersion: ptp.openshift.io/v1
kind: PtpConfig
metadata:
  name: ordinary-clock-ptp-config-worker-2 
  namespace: openshift-ptp
spec:
  profile: 
  - name: "profile1" 
    interface: "ens2f1" 
    ptp4lOpts: "-2 -m" 
    phc2sysOpts: "-a -r" 
    ptp4lConf: |-
      [global]
      #
      # Default Data Set
      #
      twoStepFlag             1
      slaveOnly               0
      priority1               128
      priority2               128
      domainNumber            24
      #utc_offset             37
      clockClass              248
      clockAccuracy           0xFE
      offsetScaledLogVariance 0xFFFF
      free_running            0
      freq_est_interval       1
      dscp_event              0
      dscp_general            0
      dataset_comparison      ieee1588
      G.8275.defaultDS.localPriority  128
      #
      # Port Data Set
      # 16 TS a second use logSyncInterval  -4
      logAnnounceInterval     1
      logSyncInterval         -4
      logMinDelayReqInterval  0
      logMinPdelayReqInterval 0
      announceReceiptTimeout  3
      syncReceiptTimeout      0
      delayAsymmetry          0
      fault_reset_interval    4
      neighborPropDelayThresh 20000000
      masterOnly              0
      G.8275.portDS.localPriority     128
      #
      # Run time options
      #
      assume_two_step         0
      logging_level           6
      path_trace_enabled      0
      follow_up_info          0
      hybrid_e2e              0
      inhibit_multicast_service       0
      net_sync_monitor        0
      tc_spanning_tree        0
      tx_timestamp_timeout    1
      unicast_listen          0
      unicast_master_table    0
      unicast_req_duration    3600
      use_syslog              1
      verbose                 0
      summary_interval        0
      kernel_leap             1
      check_fup_sync          0
      #
      # Servo Options
      #
      pi_proportional_const   0.0
      pi_integral_const       0.0
      pi_proportional_scale   0.0
      pi_proportional_exponent        -0.3
      pi_proportional_norm_max        0.7
      pi_integral_scale       0.0
      pi_integral_exponent    0.4
      pi_integral_norm_max    0.3
      step_threshold          0.0
      first_step_threshold    0.00002
      max_frequency           900000000
      clock_servo             pi
      sanity_freq_limit       200000000
      ntpshm_segment          0
      #
      # Transport options
      #
      transportSpecific       0x0
      ptp_dst_mac             01:1B:19:00:00:00
      p2p_dst_mac             01:80:C2:00:00:0E
      udp_ttl                 1
      udp6_scope              0x0E
      uds_address             /var/run/ptp4l
      #
      # Default interface options
      #
      clock_type              OC
      network_transport       UDPv4
      delay_mechanism         E2E
      time_stamping           hardware
      tsproc_mode             filter
      delay_filter            moving_median
      delay_filter_length     10
      egressLatency           0
      ingressLatency          0
      boundary_clock_jbod     0
      #
      # Clock description
      #
      productDescription      ;;
      revisionData            ;;
      manufacturerIdentity    00:00:00
      userDescription         ;
      timeSource              0xA0
    ptpSchedulingPolicy: SCHED_FIFO  
    ptpSchedulingPriority: 65 
  recommend: 
  - profile: "profile1" 
    priority: 10 
    match: 
    - nodeLabel: "node-role.kubernetes.io/worker" 
      nodeName: "worker-2.ocp4.redhat.ren" 
EOF
oc create -f /data/install/ptp.config.yaml

# oc delete -f /data/install/ptp.config.yaml

```

## create deployment ( put all together )

最终，我们可以拼装出一个完整的部署，我们的部署是一个 pod 里面有 2 个 container。一个 container 是 vbbu 应用的 container ， 按照 intel sdk 中的方法来搞，也就是尽量只把编译后的应用程序本身放进来，而不是把其他的依赖包放进来。这样镜像就会比较小，大概2G左右。 另外一个container是开发用的，因为开发组需要一个开发环境，把东西编译好，然后复制到 vbbu 应用的那个container里面去。

在这里，flexran-release-running 这个container就是最终运行用的。而flexran-dev-env就是开发环境。

目前这个版本是开发版，未来开发测试结束，将把flexran-dev-env取消，另外本地host-path的目录，也会删除，也就是本地的intel sdk都删掉。

```bash

oc new-project vbbu-demo

oc project vbbu-demo

export REG_TMP='tmp-registry.ocp4.redhat.ren:5443'

cat << EOF > /data/install/vran.intel.flexran.yaml
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: flexran-binary-release
  name: flexran-binary-release
  annotations:
    k8s.v1.cni.cncf.io/networks: intel-710-nic01-rt2,intel-710-nic02-rt2
spec:
  nodeSelector:
     kubernetes.io/hostname: worker-2.ocp4.redhat.ren
  containers:
  - securityContext:
      privileged: false
      capabilities:
        add:
          #- SYS_ADMIN
          - IPC_LOCK
          - SYS_NICE
    command: [ "/bin/sh","-c","--" ]
    args: [" sleep infinity ; "]
    # tty: true
    # stdin: true
    image: ${REG_TMP}/nepdemo/flexran_vdu:flexran-20.11-dpdk-20.11.3-ocp4.9.5-ubi-8.4
    name: flexran-release-running
    resources:
      requests:
        memory: "24Gi" 
        # intel.com/intel_fec_acc100: '1'
        hugepages-1Gi: 16Gi  
      limits:
        memory: "24Gi"
        # intel.com/intel_fec_acc100: '1'
        hugepages-1Gi: 16Gi
    volumeMounts:
    - name: hugepage
      mountPath: /hugepages
    - name: varrun
      mountPath: /var/run/dpdk
      readOnly: false
    # - name: oneapi
    #   mountPath: /opt/intel/oneapi
    #   readOnly: false
    # - name: system-studio-2019
    #   mountPath: /opt/intel/system_studio_2019
    #   readOnly: false   
    # - name: licenses
    #   mountPath: /opt/intel/licenses
    #   readOnly: false
    # - name: packagemanager
    #   mountPath: /opt/intel/packagemanager
    #   readOnly: false 
    # - name: dpdk-stable-20-11-3
    #   mountPath: /opt/dpdk-stable-20.11.3
    #   readOnly: false
    - name: flexran
      mountPath: /data/flexran
      readOnly: false   
    - name: sys
      mountPath: /sys/
      readOnly: false

  - securityContext:
      privileged: false
    command: [ "/bin/sh","-c","--" ]
    args: ["ln -s /opt/dpdk-stable-20.11.3 /opt/dpdk-20.11 ; echo 'source  /opt/intel/system_studio_2019/bin/compilervars.sh intel64' >> /root/.bashrc ; echo 'source /opt/intel/oneapi/setvars.sh' >> /root/.bashrc ; sleep infinity"]
    # tty: true
    # stdin: true
    # env:
    image: ${REG_TMP}/nepdemo/flexran_basekit:dpdk-20.11-ocp-4.9.5-ubi-8.4 
    name: flexran-dev-env
    volumeMounts:
    - name: oneapi
      mountPath: /opt/intel/oneapi
      readOnly: false
    - name: system-studio-2019
      mountPath: /opt/intel/system_studio_2019
      readOnly: false   
    - name: licenses
      mountPath: /opt/intel/licenses
      readOnly: false
    - name: packagemanager
      mountPath: /opt/intel/packagemanager
      readOnly: false   
    - name: dpdk-stable-20-11-3
      mountPath: /opt/dpdk-stable-20.11.3
      readOnly: false
    - name: flexran
      mountPath: /data/flexran
      readOnly: false            
  volumes:
  - name: hugepage
    emptyDir:
      medium: HugePages
  - name: varrun
    emptyDir: {}
  - name: dpdk-stable-20-11-3
    hostPath:
      path: "/var/baicell/dpdk-stable-20.11.3"
  - name: flexran
    hostPath:
      path: "/var/baicell/flexran"
  - name: oneapi
    hostPath:
      path: "/var/baicell/oneapi"
  - name: system-studio-2019
    hostPath:
      path: "/var/baicell/system_studio_2019"
  - name: licenses
    hostPath:
      path: "/var/baicell/licenses"
  - name: packagemanager
    hostPath:
      path: "/var/baicell/packagemanager"
  - name: sys
    hostPath:
      path: "/sys/"

EOF
oc create -f /data/install/vran.intel.flexran.yaml

# oc delete -f /data/install/vran.intel.flexran.yaml

oc rsh -c flexran-dev-env flexran-binary-release
# switch to bash, will run .bashrc, which wil bring you intel icc/icx sdk env.
# bash

```

# end

## some test, no use here
```bash
# intel icc repo
# https://www.intel.com/content/www/us/en/developer/articles/guide/installing-intel-parallel-studio-xe-runtime-2020-using-yum-repository.html


# offical oneapi docker image build
# https://hub.docker.com/r/intel/oneapi-basekit
# https://github.com/intel/oneapi-containers/blob/12932f721dd0201dfae85cacb62495924ecf42cf/images/docker/basekit/Dockerfile.centos-8

# using files/flexran.dockerfile
# buildah bud --squash -t quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4 -f flexran.dockerfile ./

# buildah push quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4

podman build --squash -t quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4 -f flexran.dockerfile ./

podman push quay.io/nepdemo/flexran_basekit:oneapi-basekit-official-ocp-4.9.5-ubi-8.4

# in container
echo 'distroverpkg=redhat-release' >> /etc/yum.conf

rpm -q --qf %{version} redhat-release;echo
# 8.4

rpm -q --provides $(rpm -q --whatprovides "system-release(releasever)")
# base-module(platform:el8)
# config(redhat-release) = 8.4-0.6.el8
# redhat-release = 8.4-0.6.el8
# redhat-release(x86-64) = 8.4-0.6.el8
# redhat-release-client
# redhat-release-computenode
# redhat-release-server
# redhat-release-workstation
# system-release = 8.4-0.6.el8
# system-release(releasever) = 8

dnf repolist
sed -i 's|enabled=1|enabled=0|g' /etc/yum/pluginconf.d/subscription-manager.conf
sed -i 's|$releasever|8.4|g' /etc/yum.repos.d/redhat.repo
sed -i '/codeready-builder-for-rhel-8-x86_64-rpms/,/\[/ s/enabled = 0/enabled = 1/' /etc/yum.repos.d/redhat.repo
mv -f /etc/yum.repos.d/ubi.repo /etc/yum.repos.d/ubi.repo.bak
```
