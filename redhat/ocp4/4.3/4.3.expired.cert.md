# rescure from expired cert

https://docs.openshift.com/container-platform/4.3/backup_and_restore/disaster_recovery/scenario-3-expired-certs.html

```bash
RELEASE_IMAGE=registry.testbed.xgvela:5443/ocp4/openshift4:4.3.5

# KAO_IMAGE=$( oc adm release info --registry-config='/var/lib/kubelet/config.json' "${RELEASE_IMAGE}" --image-for=cluster-kube-apiserver-operator )

KAO_IMAGE=registry.testbed.xgvela:5443/ocp4/openshift4:4.3.5-cluster-kube-apiserver-operator

podman run -it --network=host -v /etc/kubernetes/:/etc/kubernetes/:Z --entrypoint=/usr/bin/cluster-kube-apiserver-operator "${KAO_IMAGE}" recovery-apiserver create
# I0427 02:22:09.675618       1 apiserver.go:215] Recovery apiserver certificates will be valid for 168h0m0s
# I0427 02:22:10.018309       1 create.go:82] To access the server.
# I0427 02:22:10.018338       1 create.go:83]     export KUBECONFIG=/etc/kubernetes/static-pod-resources/recovery-kube-apiserver-pod/admin.kubeconfig

export KUBECONFIG=/etc/kubernetes/static-pod-resources/recovery-kube-apiserver-pod/admin.kubeconfig

until oc get namespace kube-system 2>/dev/null 1>&2; do echo 'Waiting for recovery apiserver to come up.'; sleep 1; done

podman run -it --network=host -v /etc/kubernetes/:/etc/kubernetes/:Z --entrypoint=/usr/bin/cluster-kube-apiserver-operator "${KAO_IMAGE}" regenerate-certificates

oc patch kubeapiserver cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge

oc patch kubecontrollermanager cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge

oc patch kubescheduler cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge

recover-kubeconfig.sh > /etc/kubernetes/kubeconfig

# copy kubeconfig to all master /etc/kubernetes/kubeconfig
# cp /etc/kubernetes/kubeconfig /home/core/wzh/
cp /home/core/kubeconfig /etc/kubernetes/kubeconfig

oc get configmap kube-apiserver-to-kubelet-client-ca -n openshift-kube-apiserver-operator --template='{{ index .data "ca-bundle.crt" }}' > /etc/kubernetes/kubelet-ca.crt

# copy kubelet-ca.crt to all master and all nodes /etc/kubernetes/kubelet-ca.crt
# cp /etc/kubernetes/kubelet-ca.crt /home/core/wzh/
cp /home/core/kubelet-ca.crt /etc/kubernetes/kubelet-ca.crt

scp core@192.168.7.13:/home/core/wzh/* ./

for host in 14 15 16 17 18; do
    scp kubeconfig core@192.168.7.$host:~/
    scp kubelet-ca.crt core@192.168.7.$host:~/
done

cat << EOF > /root/update.sh
#!/bin/bash
cp /home/core/kubeconfig /etc/kubernetes/kubeconfig
cp /home/core/kubelet-ca.crt /etc/kubernetes/kubelet-ca.crt

touch /run/machine-config-daemon-force

systemctl stop kubelet
rm -rf /var/lib/kubelet/pki /var/lib/kubelet/kubeconfig
systemctl start kubelet

EOF
bash /root/update.sh

# on all master and all nodes
touch /run/machine-config-daemon-force

# on all masters.
systemctl stop kubelet

rm -rf /var/lib/kubelet/pki /var/lib/kubelet/kubeconfig

systemctl start kubelet


# approve ocr
oc get csr | grep -v Approved
oc get csr -ojson | jq -r '.items[] | select(.status == {} ) | .metadata.name' | xargs oc adm certificate approve

# finally, and must do, after this, wait the result.
podman run -it --network=host -v /etc/kubernetes/:/etc/kubernetes/:Z --entrypoint=/usr/bin/cluster-kube-apiserver-operator "${KAO_IMAGE}" recovery-apiserver destroy

```